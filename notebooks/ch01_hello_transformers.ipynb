{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbf059a0-11fd-4be9-9050-551023042c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jingle bells, batman smells, robin laid an egg. Batmobile lost a wheel and joker got away.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text = \"Jingle bells, batman smells, robin laid an egg. Batmobile lost a wheel and joker got away.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae48d189-19ac-422c-aa8c-476b8128c52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'MISC',\n",
       "  'score': 0.5197606,\n",
       "  'word': 'Bat',\n",
       "  'start': 48,\n",
       "  'end': 51},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.51515734,\n",
       "  'word': '##mobile',\n",
       "  'start': 51,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tagger = pipeline('ner', aggregation_strategy='simple')\n",
    "outputs = ner_tagger(text)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec4c79d9-141b-4c80-bd8f-d7947e3ecd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.09772596508264542,\n",
       " 'start': 29,\n",
       " 'end': 46,\n",
       " 'answer': 'robin laid an egg'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = pipeline('question-answering')\n",
    "question = \"what season is it?\"\n",
    "outputs = reader(question=question, context=text)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fffded8-42d2-43ac-9b87-5a9dc6df1359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'What is a good following line in this song?\\n\\nJingle bells, batman smells, robin laid an egg. Batmobile lost a wheel and joker got away. This one was too good to be true.\\n\\nIt\\'s a lot like \"Sick of the Music\", but with music that\\'s so fast you take it from moment to moment. \"I\\'m not going to lie, the first few seconds would have been good.\"\\n\\nDo you know if we can call our songs more like \"The New York Post/CBS\"?\\n\\nYes, we could, we could.\\n\\nThe first song on that track was \"Gangsta Rag\", which wasn\\'t quite as good as it\\'s probably made out to be, since this part was made with very different lyrics and production values in mind. Do you know if we can call our songs more like \"The New York Post/CBS\"?Yes, we could, we could.the new beat'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline('text-generation')\n",
    "input_prompt = \"What is a good following line in this song?\\n\\n\" + text\n",
    "outputs = generator(input_prompt, max_length=200)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbfb6517-7698-4342-8b76-0473c1631227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Your max_length is set to 200, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Batmobile lost a wheel and joker got away. Jingle bells, batman smells, robin laid an egg. Batman smells and robin lays an egg. Batmobile loses a wheel. Joker gets away. Batman gets away. Robin lays egg on batman.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline('summarization')\n",
    "outputs = summarizer(text, max_length=200, clean_up_tokenization_spaces=True)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea21d61-1319-43c6-8b84-0ea9f95b8bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
